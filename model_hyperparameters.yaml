# GAML 模型超参数配置文件
# 版本: 2.0
# 更新日期: 2026-02-01

# 回归任务模型配置
regression:
  LASSO:
    alpha: [0.0001, 0.001, 0.01, 0.1, 1.0]
  
  OLS: {}
  
  Ridge:
    alpha: [0.001, 0.01, 0.1, 1.0, 10.0]
  
  ElasticNet:
    alpha: [0.001, 0.01, 0.1, 1.0]
    l1_ratio: [0.1, 0.3, 0.5, 0.7, 0.9]
  
  SVR:
    C: [0.1, 1.0, 10.0, 100.0]
    gamma: ['scale', 'auto', 0.1, 0.01]
  
  RandomForest:
    n_estimators: [50, 100, 200, 300]
    max_depth: [null, 5, 10, 20, 30]
  
  GradientBoosting:
    n_estimators: [50, 100, 200]
    learning_rate: [0.01, 0.05, 0.1]
    max_depth: [3, 4, 5, 6]
  
  XGBoost:
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 5, 7, 9]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    min_child_weight: [1, 3, 5]
    gamma: [0, 0.1, 0.2]
    reg_alpha: [0, 0.01, 0.1]
    reg_lambda: [0.5, 1, 2]
  
  LightGBM:
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 5, 7, -1]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    num_leaves: [15, 31, 63, 127]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    min_child_samples: [10, 20, 30]
    reg_alpha: [0, 0.01, 0.1]
    reg_lambda: [0, 0.01, 0.1]
  
  CatBoost:
    iterations: [50, 100, 200, 300]
    depth: [4, 6, 8, 10]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    l2_leaf_reg: [1, 3, 5, 7]
    bootstrap_type: ['Bernoulli', 'Bayesian']
    border_count: [32, 64, 128, 255]
  
  AdaBoost:
    n_estimators: [50, 100, 200]
    learning_rate: [0.1, 0.5, 1.0, 2.0]
    loss: ['linear', 'square', 'exponential']
    algorithm: ['SAMME']
  
  ExtraTrees:
    n_estimators: [50, 100, 200, 300]
    max_depth: [null, 5, 10, 15, 20]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    max_features: [0.5, 0.7, 1.0]
  
  MLP:
    hidden_layer_sizes: [[50], [100], [100, 50], [200, 100]]
    activation: ['relu', 'tanh']
    solver: ['adam', 'sgd']
    alpha: [0.0001, 0.001, 0.01]
    learning_rate: ['constant', 'adaptive']
    max_iter: [200, 300, 500]

# 二分类任务模型配置
binary_classification:
  LogisticRegression:
    C: [0.01, 0.1, 1.0, 10.0]
    solver: ['liblinear', 'lbfgs']
    max_iter: [100, 200, 500]
  
  RandomForest:
    n_estimators: [50, 100, 200, 300]
    max_depth: [null, 5, 10, 15, 20]
  
  GradientBoosting:
    n_estimators: [50, 100, 200]
    learning_rate: [0.01, 0.05, 0.1]
    max_depth: [3, 4, 5, 6]
  
  XGBoost:
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 5, 7, 9]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    min_child_weight: [1, 3, 5]
    gamma: [0, 0.1, 0.2]
    reg_alpha: [0, 0.01, 0.1]
    reg_lambda: [0.5, 1, 2]
  
  LightGBM:
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 5, 7, -1]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    num_leaves: [15, 31, 63, 127]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    min_child_samples: [10, 20, 30]
    reg_alpha: [0, 0.01, 0.1]
    reg_lambda: [0, 0.01, 0.1]
  
  CatBoost:
    iterations: [50, 100, 200, 300]
    depth: [4, 6, 8, 10]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    l2_leaf_reg: [1, 3, 5, 7]
    bootstrap_type: ['Bernoulli', 'Bayesian']
    border_count: [32, 64, 128, 255]
  
  AdaBoost:
    n_estimators: [50, 100, 200]
    learning_rate: [0.1, 0.5, 1.0, 2.0]
    algorithm: ['SAMME']
  
  ExtraTrees:
    n_estimators: [50, 100, 200, 300]
    max_depth: [null, 5, 10, 15, 20]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    max_features: [0.5, 0.7, 1.0, 'sqrt', 'log2']
  
  MLP:
    hidden_layer_sizes: [[50], [100], [100, 50], [200, 100]]
    activation: ['relu', 'tanh']
    solver: ['adam', 'sgd']
    alpha: [0.0001, 0.001, 0.01]
    learning_rate: ['constant', 'adaptive']
    max_iter: [200, 300, 500]

# 多分类任务模型配置
multiclass_classification:
  LogisticRegression:
    C: [0.01, 0.1, 1.0, 10.0]
    solver: ['lbfgs', 'newton-cg']
    max_iter: [100, 200, 500]
  
  RandomForest:
    n_estimators: [50, 100, 200, 300]
    max_depth: [null, 5, 10, 15, 20]
  
  GradientBoosting:
    n_estimators: [50, 100, 200]
    learning_rate: [0.01, 0.05, 0.1]
    max_depth: [3, 4, 5, 6]
  
  XGBoost:
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 5, 7, 9]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    min_child_weight: [1, 3, 5]
    gamma: [0, 0.1, 0.2]
    reg_alpha: [0, 0.01, 0.1]
    reg_lambda: [0.5, 1, 2]
  
  LightGBM:
    n_estimators: [50, 100, 200, 300]
    max_depth: [3, 5, 7, -1]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    num_leaves: [15, 31, 63, 127]
    subsample: [0.6, 0.8, 1.0]
    colsample_bytree: [0.6, 0.8, 1.0]
    min_child_samples: [10, 20, 30]
    reg_alpha: [0, 0.01, 0.1]
    reg_lambda: [0, 0.01, 0.1]
  
  CatBoost:
    iterations: [50, 100, 200, 300]
    depth: [4, 6, 8, 10]
    learning_rate: [0.01, 0.05, 0.1, 0.2]
    l2_leaf_reg: [1, 3, 5, 7]
    bootstrap_type: ['Bernoulli', 'Bayesian']
    border_count: [32, 64, 128, 255]
  
  AdaBoost:
    n_estimators: [50, 100, 200]
    learning_rate: [0.1, 0.5, 1.0, 2.0]
    algorithm: ['SAMME']
  
  ExtraTrees:
    n_estimators: [50, 100, 200, 300]
    max_depth: [null, 5, 10, 15, 20]
    min_samples_split: [2, 5, 10]
    min_samples_leaf: [1, 2, 4]
    max_features: [0.5, 0.7, 1.0, 'sqrt', 'log2']
  
  MLP:
    hidden_layer_sizes: [[50], [100], [100, 50], [200, 100]]
    activation: ['relu', 'tanh']
    solver: ['adam', 'sgd']
    alpha: [0.0001, 0.001, 0.01]
    learning_rate: ['constant', 'adaptive']
    max_iter: [200, 300, 500]
